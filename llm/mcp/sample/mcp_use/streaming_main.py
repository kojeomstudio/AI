import asyncio
import os

from langchain_ollama import ChatOllama
from mcp_use import MCPAgent, MCPClient

async def main():

 # Create configuration dictionary
    config = {
      "mcpServers": {
        "serena": {
            "url": "http://localhost:9121/sse",
            "headers": {
                "Authorization": "Bearer ${AUTH_TOKEN}"
                }
            }
      }
    }

    # Create MCPClient from configuration dictionary
    client = MCPClient.from_dict(config)

# Initialize local Ollama model
    llm = ChatOllama(
    model="qwen3:8b",
    base_url="http://localhost:11434/",  # Default Ollama URL
    temperature=0.7
    )

    agent = MCPAgent(llm=llm, client=client)

    async for item in agent.stream("c#ìœ¼ë¡œ ì‘ì„±ëœ ê²Œì„ ì„œë²„ ì½”ë“œë¥¼ ëª¨ë‘ ê²€ìƒ‰í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”. ë°˜ë“œì‹œ í•œê¸€ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."):
        if isinstance(item, str):
            # Final result
            print(f"\nâœ… Final Result:\n{item}")
        else:
            # Intermediate step (action, observation)
            action, observation = item
            print(f"\nğŸ”§ Tool: {action.tool}")
            print(f"ğŸ“ Input: {action.tool_input}")
            print(f"ğŸ“„ Result: {observation[:100]}{'...' if len(observation) > 100 else ''}")

    print("\nğŸ‰ Done!")

if __name__ == "__main__":
    asyncio.run(main())